{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "from collections import Counter\n",
    "import codecs\n",
    "from nltk import word_tokenize\n",
    "import nltk\n",
    "from nltk.collocations import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = codecs.open('C:\\\\Users\\\\Fabian\\\\Desktop\\\\NLP\\\\de_text\\\\de_text.train','r', 'utf-8');\n",
    "text_train = f.read()\n",
    "    \n",
    "words_train = re.findall(r'\\w+', text_train);\n",
    "words_train = [w.lower() for w in words_train];\n",
    "word_counts = Counter(words_train);\n",
    "\n",
    "words_train_complete = nltk.wordpunct_tokenize(text_train); #take also the empty words and punctuation as words\n",
    "words_train_complete = [w.lower() for w in words_train_complete];\n",
    "word_count_complete = Counter(words_train_complete);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a) 20 most frequent words: [('die', 29077), ('der', 28125), ('und', 16531), ('in', 14695), ('den', 9724), ('das', 9044), ('von', 8002), ('zu', 7245), ('mit', 7126), ('im', 6454), ('auf', 6272), ('für', 6180), ('sich', 6158), ('ist', 6040), ('nicht', 5852), ('ein', 5724), ('des', 5209), ('dem', 5145), ('es', 4888), ('eine', 4763)]\n",
      "\n",
      "a) 20 most frequent words complete: [('%^%', 100000), ('%$%', 100000), ('.', 52222), (',', 45462), ('die', 29077), ('der', 28125), ('und', 16531), ('-', 15939), ('in', 14695), ('\"', 13289), ('den', 9724), ('das', 9044), ('von', 8002), ('zu', 7245), ('mit', 7126), ('im', 6454), ('auf', 6272), ('für', 6180), ('sich', 6158), ('ist', 6040)]\n"
     ]
    }
   ],
   "source": [
    "print('a) 20 most frequent words:',word_counts.most_common(20));\n",
    "print()\n",
    "print('a) 20 most frequent words complete:',word_count_complete.most_common(20));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = codecs.open('C:\\\\Users\\\\Fabian\\\\Desktop\\\\NLP\\\\de_text\\\\de_text.test','r', 'utf-8');\n",
    "text_test = f.read();\n",
    "\n",
    "words_test = re.findall(r'\\w+', text_test);\n",
    "words_test = [w.lower() for w in words_test]\n",
    "\n",
    "words_test_complete = nltk.wordpunct_tokenize(text_test); #take also the empty words and punctuation as words\n",
    "words_test_complete = [w.lower() for w in words_test_complete];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b) percentage of words seen in the train set but not in the test set: 53.323425956614244 %\n"
     ]
    }
   ],
   "source": [
    "train_set = set(words_train);\n",
    "test_set = set(words_test);\n",
    "intersections = train_set.intersection(test_set)\n",
    "words_only_in_test = test_set-intersections;\n",
    "print('b) percentage of words seen in the train set but not in the test set:', 100* len(words_only_in_test)/len(test_set),'%') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Bigram stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "finder_train = BigramCollocationFinder.from_words(words_train_complete); #not sure if complete word set or normal word set (Without '%$%', '%$%')\n",
    "scored_bigrams_train = finder_train.score_ngrams(bigram_measures.raw_freq)\n",
    "sorted(bigrams for bigrams, score in scored_bigrams_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c) 20 most frequent Bigrams in Train: [(('%$%', '%$%'), 0.04370694319758248), (('%^%', '%^%'), 0.04370694319758248), (('%$%', '%^%'), 0.04370606905871853), (('.', '%$%'), 0.04116756979780294), (('%^%', 'die'), 0.004424016790459299), ((',', 'die'), 0.003410889847139337), (('in', 'der'), 0.0024510853745204255), (('%^%', 'der'), 0.002404756014730988), (('%^%', 'das'), 0.0017106897567533783), ((',', 'der'), 0.0016425069253651497), (('\"', ','), 0.0016241500092221651), (('%^%', '\"'), 0.0016171568983105518), ((',', 'dass'), 0.0013977480434586877), (('in', 'den'), 0.0013785169884517514), (('für', 'die'), 0.0013050893238798129), (('%^%', 'in'), 0.00120281507679747), ((',', 'daß'), 0.0011765909108789204), (('?', '%$%'), 0.0010839321913000456), (('\"', '%$%'), 0.0010262390262792366), (('.', '\"'), 0.001013126943319962)]\n",
      "number of Bigrams:  474236\n"
     ]
    }
   ],
   "source": [
    "print ('c) 20 most frequent Bigrams in Train:',scored_bigrams_train[0:20])\n",
    "print ('number of Bigrams: ',len(scored_bigrams_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bigram_train_set = set(nltk.bigrams(words_train_complete)) \n",
    "bigram_test_set = set(nltk.bigrams(words_test_complete))\n",
    "#print(len(bigram_test_set))\n",
    "#print(len(bigram_train_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d) percentage of bigrams seen in the train set but not in the test set: 76.19720701218218 %\n"
     ]
    }
   ],
   "source": [
    "only_in_test_set = bigram_test_set-bigram_train_set\n",
    "print('d) percentage of bigrams seen in the train set but not in the test set:', 100* len(only_in_test_set)/len(bigram_test_set),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lines = tuple(codecs.open('C:\\\\Users\\\\Fabian\\\\Desktop\\\\NLP\\\\de_text\\\\de_text.test','r', 'utf-8'))\n",
    "lines = [line.rstrip('\\n') for line in lines] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f) Sentences that contain a bigram not seen in the training data: 38657  -> zero probability\n"
     ]
    }
   ],
   "source": [
    "count = 0;\n",
    "for line in lines:\n",
    "    bigrams_of_sentence = set(nltk.bigrams(nltk.wordpunct_tokenize(line)))\n",
    "    for bigram in bigrams_of_sentence:\n",
    "        if bigram in only_in_test_set:  \n",
    "            #print(line,bigram)\n",
    "            count = count+1;\n",
    "            break;\n",
    "            \n",
    "print('f) Sentences that contain a bigram not seen in the training data:',count,' -> zero probability')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Trigram stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trigram_measures = nltk.collocations.TrigramAssocMeasures();\n",
    "finder_trigrams = TrigramCollocationFinder.from_words(words_train_complete);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 most frequent Trigrams: [(('%$%', '%$%', '%^%'), 0.04370606905871853), (('%$%', '%^%', '%^%'), 0.04370606905871853), (('.', '%$%', '%$%'), 0.04116756979780294), (('%^%', '%^%', 'die'), 0.004424016790459299), (('%^%', '%^%', 'der'), 0.002404756014730988), (('%^%', '%^%', 'das'), 0.0017106897567533783), (('%^%', '%^%', '\"'), 0.0016171568983105518), (('%^%', '%^%', 'in'), 0.00120281507679747), (('?', '%$%', '%$%'), 0.0010839321913000456), (('\"', '%$%', '%$%'), 0.0010262390262792366), (('werden', '.', '%$%'), 0.0009134751128294739), (('.', '\"', '%$%'), 0.000908230279645764), (('\"', '.', '%$%'), 0.0007910956718762429), (('%^%', '%^%', 'und'), 0.0007631232282297901), (('%^%', '%^%', 'es'), 0.0007543818395902736), (('%^%', '%^%', 'er'), 0.000701059368889223), (('%^%', '%^%', 'im'), 0.0006853248693380933), (('%^%', '%^%', 'sie'), 0.0006730869252427702), (('%^%', '%^%', 'auch'), 0.0006250092877254295), (('%^%', '%^%', 'ein'), 0.0005874213165755085)]\n"
     ]
    }
   ],
   "source": [
    "scored_trigrams = finder_trigrams.score_ngrams(trigram_measures.raw_freq)\n",
    "#sorted(trigram for trigram, score in scored_trigrams)\n",
    "print ('20 most frequent Trigrams:',scored_trigrams[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trigram_train_set = set(nltk.trigrams(words_train_complete)) \n",
    "trigram_test_set = set(nltk.trigrams(words_test_complete))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e) percentage of trigrams seen in the train set but not in the test set: 89.66927365482084 %\n"
     ]
    }
   ],
   "source": [
    "only_in_test_set_trigram = trigram_test_set-trigram_train_set\n",
    "print('e) percentage of trigrams seen in the train set but not in the test set:', 100* len(only_in_test_set_trigram)/len(trigram_test_set),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trigram_train_list = list(nltk.trigrams(words_train_complete)) \n",
    "trigram_test_list = list(nltk.trigrams(words_test_complete))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getIndices(trigram, trigram_list):\n",
    "    return [i for i, x in enumerate(trigram_list) if x == trigram]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139\n"
     ]
    }
   ],
   "source": [
    "print(len(getIndices(('in', 'diesem', 'jahr'),trigram_train_list))) #example for occurrence of trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 47095, 0, 86, 0, 0, 0, 0, 0, 0, 0, 14, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "trigramNo = list()\n",
    "bigramNo = list()\n",
    "for line in lines[:1]:\n",
    "    words_of_sentence = nltk.wordpunct_tokenize(line)\n",
    "    trigrams_of_sentence = set(nltk.trigrams(words_of_sentence))\n",
    "    bigrams_of_sentence = set(nltk.bigrams(words_of_sentence))  \n",
    "    \n",
    "    for trigram in trigrams_of_sentence:\n",
    "        trigramNo.append(len(getIndices(trigram,trigram_train_list)))\n",
    "        \n",
    "print(trigramNo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lamda0 = 10**(-10);\n",
    "lamda1 = 0.01;\n",
    "lamda2 = 0.2;\n",
    "lamda3 = 1-(lamda0+lamda1+lamda2)\n",
    "\n",
    "def getTrigramProb(trigram_count,bigram_count):\n",
    "    return lamda3*trigram_count/bigram_count\n",
    "\n",
    "# no time to finish g) .. sadly"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
